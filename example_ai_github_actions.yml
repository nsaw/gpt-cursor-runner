name: AI Code Review and Analysis
on:
  pull_request:
    types: [opened, synchronize]
  push:
    branches: [main, develop]

jobs:
  ai-code-review:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Get changed files
        id: changed-files
        uses: tj-actions/changed-files@v41
        with:
          files: |
            **/*.py
            **/*.js
            **/*.ts
            **/*.java
            **/*.cpp
            **/*.c
            **/*.go
            **/*.rs
            **/*.rb
      
      - name: AI Code Review with OpenAI
        if: steps.changed-files.outputs.any_changed == 'true'
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Create a script for AI code review
          cat > ai_review.py << 'EOF'
          import os
          import json
          import requests
          import base64
          
          # Get changed files
          changed_files = """${{ steps.changed-files.outputs.all_changed_files }}"""
          
          # OpenAI API configuration
          openai_api_key = os.getenv('OPENAI_API_KEY')
          github_token = os.getenv('GITHUB_TOKEN')
          
          if not openai_api_key:
              print("No OpenAI API key found")
              exit(1)
          
          # Read and analyze each changed file
          for file_path in changed_files.split():
              if os.path.exists(file_path):
                  with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                      file_content = f.read()
                  
                  # Prepare OpenAI request
                  headers = {
                      'Authorization': f'Bearer {openai_api_key}',
                      'Content-Type': 'application/json'
                  }
                  
                  data = {
                      'model': 'gpt-4o',
                      'messages': [
                          {
                              'role': 'system',
                              'content': 'You are an expert code reviewer. Analyze the code for bugs, security issues, performance problems, and code quality. Provide specific, actionable feedback.'
                          },
                          {
                              'role': 'user',
                              'content': f'Review this code from file {file_path}:\n\n{file_content}'
                          }
                      ],
                      'max_tokens': 1000,
                      'temperature': 0.1
                  }
                  
                  try:
                      response = requests.post(
                          'https://api.openai.com/v1/chat/completions',
                          headers=headers,
                          json=data,
                          timeout=30
                      )
                      
                      if response.status_code == 200:
                          result = response.json()
                          review_content = result['choices'][0]['message']['content']
                          
                          print(f"\n=== Review for {file_path} ===")
                          print(review_content)
                          print("=" * 50)
                          
                          # Save review to file for PR comment
                          with open(f'review_{file_path.replace("/", "_")}.md', 'w') as rf:
                              rf.write(f"## AI Code Review: {file_path}\n\n")
                              rf.write(review_content)
                              rf.write("\n\n---\n*This review was generated by AI*")
                      else:
                          print(f"Error analyzing {file_path}: {response.status_code}")
                          print(response.text)
                  
                  except Exception as e:
                      print(f"Error processing {file_path}: {str(e)}")
          EOF
          
          # Run the AI review script
          python ai_review.py
      
      - name: AI Security Analysis with Claude
        if: steps.changed-files.outputs.any_changed == 'true'
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          # Create security analysis script
          cat > security_analysis.py << 'EOF'
          import os
          import json
          import requests
          
          # Get changed files
          changed_files = """${{ steps.changed-files.outputs.all_changed_files }}"""
          
          # Anthropic API configuration
          anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')
          
          if not anthropic_api_key:
              print("No Anthropic API key found")
              exit(1)
          
          # Analyze each changed file for security issues
          for file_path in changed_files.split():
              if os.path.exists(file_path):
                  with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                      file_content = f.read()
                  
                  # Prepare Anthropic request
                  headers = {
                      'Authorization': f'Bearer {anthropic_api_key}',
                      'Content-Type': 'application/json',
                      'X-API-Key': anthropic_api_key
                  }
                  
                  data = {
                      'model': 'claude-3-5-sonnet-20241022',
                      'max_tokens': 1000,
                      'messages': [
                          {
                              'role': 'user',
                              'content': f'Analyze this code for security vulnerabilities, potential exploits, and security best practices. Focus on: SQL injection, XSS, authentication flaws, data validation, and other security issues.\n\nFile: {file_path}\n\nCode:\n{file_content}'
                          }
                      ]
                  }
                  
                  try:
                      response = requests.post(
                          'https://api.anthropic.com/v1/messages',
                          headers=headers,
                          json=data,
                          timeout=30
                      )
                      
                      if response.status_code == 200:
                          result = response.json()
                          security_analysis = result['content'][0]['text']
                          
                          print(f"\n=== Security Analysis for {file_path} ===")
                          print(security_analysis)
                          print("=" * 50)
                          
                          # Save security analysis
                          with open(f'security_{file_path.replace("/", "_")}.md', 'w') as sf:
                              sf.write(f"## Security Analysis: {file_path}\n\n")
                              sf.write(security_analysis)
                              sf.write("\n\n---\n*This analysis was generated by Claude AI*")
                      else:
                          print(f"Error analyzing {file_path}: {response.status_code}")
                          print(response.text)
                  
                  except Exception as e:
                      print(f"Error processing {file_path}: {str(e)}")
          EOF
          
          # Run the security analysis script
          python security_analysis.py
      
      - name: Comment on PR with AI Reviews
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const path = require('path');
            
            // Find all review files
            const reviewFiles = fs.readdirSync('.').filter(file => 
              file.startsWith('review_') && file.endsWith('.md')
            );
            
            const securityFiles = fs.readdirSync('.').filter(file => 
              file.startsWith('security_') && file.endsWith('.md')
            );
            
            let comment = '## 🤖 AI Code Review Results\n\n';
            
            // Add code reviews
            if (reviewFiles.length > 0) {
              comment += '### 📝 Code Review\n\n';
              reviewFiles.forEach(file => {
                const content = fs.readFileSync(file, 'utf8');
                comment += content + '\n\n';
              });
            }
            
            // Add security analysis
            if (securityFiles.length > 0) {
              comment += '### 🔒 Security Analysis\n\n';
              securityFiles.forEach(file => {
                const content = fs.readFileSync(file, 'utf8');
                comment += content + '\n\n';
              });
            }
            
            if (reviewFiles.length > 0 || securityFiles.length > 0) {
              // Post comment on PR
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            }
      
      - name: AI Code Quality Check
        if: steps.changed-files.outputs.any_changed == 'true'
        run: |
          echo "## AI Code Quality Summary" > quality_report.md
          echo "### Files Analyzed: ${{ steps.changed-files.outputs.all_changed_files_count }}" >> quality_report.md
          echo "### AI Models Used:" >> quality_report.md
          echo "- OpenAI GPT-4o for code review" >> quality_report.md
          echo "- Claude 3.5 Sonnet for security analysis" >> quality_report.md
          echo "### Status: ✅ Analysis Complete" >> quality_report.md
          
          cat quality_report.md
      
      - name: Upload AI Analysis Reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ai-analysis-reports
          path: |
            *.md
            quality_report.md
          retention-days: 30

  ai-code-metrics:
    runs-on: ubuntu-latest
    if: github.event_name == 'push'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: AI Code Metrics Analysis
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          # Analyze overall code quality metrics
          cat > metrics_analysis.py << 'EOF'
          import os
          import subprocess
          import requests
          import json
          
          # Get repository stats
          try:
              # Count lines of code
              result = subprocess.run(['find', '.', '-name', '*.py', '-o', '-name', '*.js', '-o', '-name', '*.ts', '-o', '-name', '*.java', '|', 'xargs', 'wc', '-l'], 
                                    capture_output=True, text=True, shell=True)
              lines_of_code = result.stdout.strip().split('\n')[-1] if result.stdout else "0"
              
              # Count files
              result = subprocess.run(['find', '.', '-type', 'f', '-name', '*.py', '-o', '-name', '*.js', '-o', '-name', '*.ts', '-o', '-name', '*.java', '|', 'wc', '-l'], 
                                    capture_output=True, text=True, shell=True)
              file_count = result.stdout.strip()
              
              openai_api_key = os.getenv('OPENAI_API_KEY')
              
              if openai_api_key:
                  # Get AI insights on code metrics
                  headers = {
                      'Authorization': f'Bearer {openai_api_key}',
                      'Content-Type': 'application/json'
                  }
                  
                  data = {
                      'model': 'gpt-4o',
                      'messages': [
                          {
                              'role': 'system',
                              'content': 'You are a code metrics analyst. Provide insights on code quality, maintainability, and recommendations.'
                          },
                          {
                              'role': 'user',
                              'content': f'Analyze a codebase with {file_count} files and approximately {lines_of_code} lines of code. Provide insights on code quality, maintainability recommendations, and best practices.'
                          }
                      ],
                      'max_tokens': 500,
                      'temperature': 0.1
                  }
                  
                  response = requests.post(
                      'https://api.openai.com/v1/chat/completions',
                      headers=headers,
                      json=data,
                      timeout=30
                  )
                  
                  if response.status_code == 200:
                      result = response.json()
                      metrics_analysis = result['choices'][0]['message']['content']
                      
                      print("=== AI Code Metrics Analysis ===")
                      print(f"Files: {file_count}")
                      print(f"Lines of Code: {lines_of_code}")
                      print("\nAI Insights:")
                      print(metrics_analysis)
                      
                      # Save metrics report
                      with open('metrics_report.md', 'w') as f:
                          f.write("# Code Metrics Report\n\n")
                          f.write(f"**Files Analyzed:** {file_count}\n")
                          f.write(f"**Lines of Code:** {lines_of_code}\n\n")
                          f.write("## AI Analysis\n\n")
                          f.write(metrics_analysis)
                          f.write("\n\n---\n*Generated by AI Code Metrics Analysis*")
                  else:
                      print(f"Error getting AI metrics: {response.status_code}")
              else:
                  print("No OpenAI API key found for metrics analysis")
          
          except Exception as e:
              print(f"Error in metrics analysis: {str(e)}")
          EOF
          
          python metrics_analysis.py